Abstract
	Machine learning (ML) has grown over a wide range of sectors such as finance, education, communication, transportation, retail, and healthcare. Due to this, researchers have developed a variety of algorithms to analyze a large amount of data and derive quantifiable insights from it. The organizations may have data in text, image, audio, video, and numeric formats and machine learning can be used to create programs for speech recognition, natural language processing, computer vision, and recommendation systems. In this paper, k-Nearest Neighbor (kNN) machine learning algorithm is proposed to solve classification problems. KNN classifier groups the data into clusters 
and classifies the input data based on its similarity with trained data. The input is assigned to that class with which it shares the most nearest neighbors. The model is integrated with Neocortex API and gets the input data sequence from its Multi-sequence learning model. In the primary stage, the model gets trained and then produces the sequential output based on the KNN model with 80-85% accuracy. Additionally, the design procedure, challenges, and enhancements to improve model accuracy are discussed in the paper.

Introduction
	The aim of machine learning is to create statistical models and algorithms that allow computers to learn from data without being explicitly programmed. More precisely, these statistical models and algorithms generate the "learn" method, which helps the computer in making predictions about the future based on data. Supervised, unsupervised, and reinforcement learning are the three main types of machine learning.

1)	Supervised learning: The supervised machine learning algorithms learn from input variables and a pre-labeled dataset to predict an output variable. 

2)	Unsupervised Learning: The algorithms which learn from unlabeled data, where the input features are given but the output labels are unknown are known as unsupervised learning. 

3)	Reinforcement Learning: This type of algorithm learns by trial and error and is often used in situations where an agent interacts with an environment to achieve a specific goal. 
	
	Besides other supervised machine learning algorithms, the k-nearest neighbor (KNN) algorithm is widely used for classification and regression problems. This paper is focused on the KNN algorithm used as a classifier, i.e. KNN Classifier. It is a non-parametric classification algorithm, i.e. it does not make any presumptions about the dataset. It is known for its simplicity and effectiveness. A labeled training dataset is provided where the data points are categorized into various classes so that the class of unlabeled data can be predicted.
	In classification, different characteristics determine the class to which the unlabeled data belongs. It is used to classify data based on the closest or neighboring training examples in a giver region. It uses Euclidean distance to calculate its nearest neighbors.  
	KNN classifier works by first selecting the value of K, the number of nearest neighbors to consider when making a prediction, which plays an important role in classifying the unlabeled data. There are many ways to decide the values for 'K', but in this paper, the classifier is run multiple times with different values to see which value gives the most effective result. Given a new observation, the algorithm calculates the Euclidean Distance between the new observation and all the existing observations in the training set. It then calculates the K nearest neighbors that are closest to the new observation and the majority among the neighboring data decides the classification for the new input. It is simple and effective but the choice of value for K can significantly affect the performance of the algorithm.
